apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ template "hbase-k8s.config.fullname" . }}
  labels:
    app: {{ template "hbase-k8s.config.name" . }}
    chart: {{ template "hbase-k8s.subchart" . }}
    release: {{ .Release.Name }}
data:
  hbase-site.xml: |
    <configuration>
    {{- range $key, $value := .Values.customHbaseConfig.hbaseSite }}
      <property>
        <name>{{ $key }}</name>
        <value>{{ $value }}</value>
      </property>
    {{- end }}
      <property>
        <name>zookeeper.znode.parent</name>
        <value>/hbase</value>
      </property>
      <property>
        <name>hbase.rootdir</name>
        <value>{{ template "hbase-rootdir" . }}</value>
      </property>
      <property>
        <name>hbase.cluster.distributed</name>
        <value>true</value>
      </property>
      <property>
        <name>hbase.zookeeper.quorum</name>
        <value>{{ template "zookeeper-quorum" . }}</value>
      </property>
    </configuration>

  bootstrap.sh: |
    #!/usr/bin/env bash
    # Exit on error. Append "|| true" if you expect an error.
    set -o errexit
    # Exit on error inside any functions or subshells.
    set -o errtrace
    # Do not allow use of undefined vars. Use ${VAR:-} to use an undefined VAR
    set -o nounset
    # Catch an error in command pipes. e.g. mysqldump fails (but gzip succeeds)
    # in `mysqldump |gzip`
    set -o pipefail
    # Turn on traces, useful while debugging.
    set -o xtrace

    . $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh

    # Copy config files from volume mount

    _HBASE_HOME=/opt/hbase

    for f in hbase-site.xml; do
      if [[ -e ${HBASE_CUSTOM_CONF_DIR}/$f ]]; then
        cp ${HBASE_CUSTOM_CONF_DIR}/$f ${_HBASE_HOME}/conf/$f
      else
        echo "ERROR: Could not find $f in $HBASE_CUSTOM_CONF_DIR"
        exit 1
      fi
    done

    for f in core-site.xml hdfs-site.xml; do
      if [[ -e ${HADOOP_CUSTOM_CONF_DIR}/$f ]]; then
        cp ${HADOOP_CUSTOM_CONF_DIR}/$f ${_HBASE_HOME}/conf/$f
      else
        echo "ERROR: Could not find $f in HADOOP_CUSTOM_CONF_DIR"
        exit 1
      fi
    done

    # installing libraries if any - (resource urls added comma separated to the ACP system variable)
    cd $HADOOP_PREFIX/share/hadoop/common ; for cp in ${ACP//,/ }; do  echo == $cp; curl -LO $cp ; done; cd -

    if [[ "${MY_POD}" =~ "master" ]]; then
      ${_HBASE_HOME}/bin/hbase-daemon.sh --config ${_HBASE_HOME}/conf start master
    fi

    if [[ "${MY_POD}" =~ "regionserver" ]]; then
      ${_HBASE_HOME}/bin/hbase-daemon.sh --config ${_HBASE_HOME}/conf start regionserver
    fi

    if [[ "${MY_POD}" =~ "restserver" ]]; then
      ${_HBASE_HOME}/bin/hbase-daemon.sh --config ${_HBASE_HOME}/conf start rest
    fi

    if [[ "${MY_POD}" =~ "thriftserver" ]]; then
      ${_HBASE_HOME}/bin/hbase-daemon.sh --config ${_HBASE_HOME}/conf start thrift
    fi

    # A common approach is to keep the container alive
    tail -f /dev/null